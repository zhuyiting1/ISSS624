{
  "hash": "ccef43298ad1a3154a991c230bbc7768",
  "result": {
    "markdown": "---\ntitle: \"In-class Exercise 3\"\nauthor: Zhu Yiting\ndate: \"3 Dec 2022\"\nexecute: \n  warning: false\n  message: false\n  freeze: auto\nformat: html\neditor: visual\n---\n\n\n## Quarto 101\n\n> execute:\n>\n> echo: false\n\nAbove is to by default [not display]{.underline} any code chunks in the global environment, when keyed into the top part of the Quarto document.\n\n## Run-through of Hands-on Exercise 3\n\n### [R packages]{.underline}\n\n> **sf**: do data import and export\n>\n> **rgdal**: do transformation, change from 1 data type to another\n>\n> **spdep**: used to create spanning trees (including SKATER)\n>\n> -   last week also used for computation of spatial autocorrelation, very rich package)\n>\n> **readr**: reading of csv, read text data in and out of R\n>\n> -   if we want to read excel file (.xlsx), especially excel workbook with multiple worksheets -\\> should use **readexcel**\n>\n> statistical packages -\\> use package called **heaven** (?) to bring into R\n>\n> **ggplot2**: create plots for statistical methods\n>\n> **tmap**: mapping device\n>\n> **coorplot**: build correlation plot\n>\n> **ggpubr**: glue up multiple\n>\n> **heatmaply**: plotlib (?) version to do interactive heatmap in multidimension\n>\n> **clusterGeo**: soft spatially constrained clustering algorithm package\n>\n> **factoextra**: mainly for factor analysis, but also have a very nice visual for us to understand how the cluster change using the different clustering methods\n>\n> *PCA vs factor analysis: PCA rotation is 90 degrees so that newly transformed variables are as far as possible, factor analysis have other rotation methods such as value max (?)*\n\n**NbClust**: access hierarchical clustering results\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(rgdal, spdep, tmap, sf, \n               ggpubr, cluster, factoextra, NbClust, \n               heatmaply, corrplot, psych, tidyverse, ClustGeo)\n```\n:::\n\n\n### [Loading shapefile data]{.underline}\n\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. We can import it into the R environment using [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf**. We also use the piping function *%\\>%* from **dplyr** and perform *filter()* to extract only the data for the Shan state. This is done in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- st_read(dsn = \"data/geospatial\",\n                   layer = \"myanmar_township_boundaries\") %>% \n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\zhuyiting1\\ISSS624\\In-class_Ex\\In-class_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n> Have a habit of examining the data:\n>\n> -   Polygon\n>\n> -   Decimal degree format\n>\n> -   WGS84\n>\n> Click on file \\|\\>arrow in the Environment pane to check the variables (field name). Alternatively, use *str()* to show the field names.\n>\n> To check the full data table, click on the object in the Environment pane. It includes all attribute values in the dbf file + geometry from shp file.\n>\n> *Setting CRS: important to change to projected CRS when doing distance-based weight matrix. Not required for contiguity-based weight matrix as the CRS does not affect the boundaries touching.*\n>\n> Code explained:\n>\n> *%\\>%*: piping - glue different functions together\n>\n> -   As good practice, push the code after *%\\>%* to the next line for neatness.\n\n### [Loading csv data]{.underline}\n\nThe csv file is imported using [*read_csv()*](https://readr.tidyverse.org/reference/read_delim.html) of **readr** using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nict <- read_csv(\"data/aspatial/Shan-ICT.csv\")\n```\n:::\n\n\n> *read_csv()* of **readr** used instead of *read.csv()* of **Base R**\n>\n> -   Former is a readr function -\\> retains the original field names.\n>\n>     -   Use \\` \\` to encapsulate complete variable names with space\n>\n> -   Latter changes the variable names by replacing and space with period.\n\n### [Calculation of derived ICT penetration rates]{.underline}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%\n  rename(`DT_PCODE`=`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n```\n:::\n\n\n> 6 new variables added to `ict_derived` using *mutate()*.\n>\n> x1000 -\\> in social science, usually the units are no. of handphones by per 1'000 households\n>\n> Can x100 if computing % households with handphones.\n>\n> *rename()* changes the variable names to match that of the shapefile to do join later (e.g. change from `Distinct Pcode` to `DT_PCODE`.\n\n### [Joining of data]{.underline}\n\nWe combine both sets of data into a single data.frame using [*left_join()*](https://dplyr.tidyverse.org/reference/mutate-joins.html) of **dplyr**, which appends the second data.frame to the first based on the observations in the first. The `shan_sf` simple feature data.frame will be used as the base data object, so that the geometry is retained, and the `ict_derived` data.frame will be used as the join table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- left_join(shan_sf, \n                     ict_derived, \n                     by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n```\n:::\n\n\n> We need to define the variable names to join (`by=`) , if we did not rename the variables to align them previously.\n\n### [Visualisation methods]{.underline}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = shan_sf, \n       aes(x = `RADIO`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-6-1.png){width=384}\n:::\n:::\n\n\n> By using ggplot() directly without assigning it to an ouput object (e.g. plot1 \\<-), it is not saved and only shown when rendered (good for quick view). Assign to object if want to call it later.\n>\n> If don't want to run the code to plot the graph when rendering (set `#| eval: false`), can find the html image file which is produced the first time the code chunk was rendered, and paste the code in the report :)\n\n### [Correlation analysis]{.underline}\n\nWe use [*corrplot.mixed()*](https://www.rdocumentation.org/packages/corrplot/versions/0.92/topics/corrplot.mixed) of [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) to visualise and analyse the correlation of the input variables, using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n> If ellipse is thin and colour is dark -\\> high correlation.\n>\n> `cor(ict_derived[,12:17])` -\\> to pick out columns 12 to 17 only for data.frame and then plotting of correlation plot.\n\n### [Cluster analysis]{.underline}\n\nThe code chunk below will be used to extract the clustering variables from the *shan_sf* simple feature object into data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n```\n:::\n:::\n\n\n> Use the *select()* function to extract the variables out (because we don't need the rest).\n>\n> `st_set_geometry(Null)` drops the geometric column so that it does not go into the data frame which does not work in the hierarchical clustering.\n\nNext, we need to change the rows by township name instead of row number by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n```\n:::\n:::\n\n\nNow, we will delete the TS.x field (representing township) which is a duplicate of the row names now, by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n```\n:::\n:::\n\n\n> Do this to make a tidy data frame so that all the columns are just the variables for clustering analysis.\n>\n> `TS.x` kept and shifted to row name instead of simply deleting because we need it later (displayed in the dendogram instead of just numbers).\n\n### [Proximity matrix]{.underline}\n\nThe code chunk below is used to compute the proximity matrix using `euclidean` method.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat <- dist(shan_ict, method = 'euclidean')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat\n```\n:::\n\n\n> Values represent the proximity matrix between towns in the top row and left-most column. The matrix is symmetrical along the diagonal. The value for the diagonal is 0.\n\n### [Hierarchical clustering]{.underline}\n\nThe code chunk below performs hierarchical cluster analysis using `ward.D` method. The hierarchical clustering output is stored in an object of class **hclust** which describes the tree produced by the clustering process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n```\n:::\n\n\n> The code is simple as it only requires 2 arguments: the proximity matrix and the clustering method.\n\nWe can then plot the tree by using *plot()* of **R Graphics** as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hclust_ward, cex = 0.6)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n> Both *hclust()* and *plot()* are of **Base R** (*plot()* from Base R **Graphics**), don't need to tell *plot()* how to plot, it knows! :D\n>\n> `cex = 0.6` scales the resolution to 60% of the full resolution. Useful when the dendogram looks too cluttered and the clusters cannot be read.\n\n### [Finding Optimal Clustering Algorithm]{.underline}\n\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n```\n:::\n:::\n\n\nWith reference to the output above, we can see that Ward's method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used.\n\n> Highest value = most optimal model\n>\n> *Functional programming:*\n>\n> Want to run all four hierarchical clustering algorithms in 1 go -\\> create an object `m` and `names(m)`\n>\n> Then we define a function with the syntax `function(x){ }`\n>\n> The function is to substitute each element (hierarchical clustering method) in the list `m` as `method = x` in the function for *agnes()* to compute agglomerative hierarchical clustering of the data set.\n>\n> Similar to looping in conventional programming.\n\n### [Determining Optimal Cluster]{.underline}\n\nTo compute the gap statistic, [*clusGap()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/clusGap) of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package will be used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.677830 0.2707006 0.03692273\n [2,] 8.130029 8.346462 0.2164322 0.04088387\n [3,] 7.992265 8.200253 0.2079877 0.03762167\n [4,] 7.862224 8.079170 0.2169462 0.04018998\n [5,] 7.756461 7.977981 0.2215201 0.04229538\n [6,] 7.665594 7.890134 0.2245409 0.04501316\n [7,] 7.590919 7.812990 0.2220709 0.04364077\n [8,] 7.526680 7.739537 0.2128575 0.04477188\n [9,] 7.458024 7.670476 0.2124519 0.04623855\n[10,] 7.377412 7.603947 0.2265346 0.04762720\n```\n:::\n:::\n\n\nAlso note that the [*hcut*](https://rpkgs.datanovia.com/factoextra/reference/hcut.html) function used is from [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.\n\nNext, we can visualise the plot by using [*fviz_gap_stat()*](https://rpkgs.datanovia.com/factoextra/reference/fviz_nbclust.html) of [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_gap_stat(gap_stat)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n> If we follow the statistics strictly, 2 clusters would be the best. However, we know that we should not have less than 3 clusters as it is a multivariate analysis. Hence, by visual assessment, cluster numbers 5 and 6 may work better.\n\n### [Mapping of Hierarchical Clusters]{.underline}\n\nWith closed examination of the dendragram above, we have decided to retain six clusters.\n\n[*cutree()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cutree.html) of **Base R** will be used in the code chunk below to derive a 6-cluster model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(hclust_ward, k=6))\n```\n:::\n\n\nIn order to visualise the clusters, the *groups* object need to be appended onto `shan_sf` simple feature object.\n\nThe code chunk below form the join in three steps:\n\n-   the `groups` list object will be converted into a matrix;\n\n-   *cbind()* is used to append `groups` matrix onto `shan_sf` to produce an output simple feature object called `shan_sf_cluster`; and\n\n-   *rename()* of **dplyr** package is used to rename `as.matrix.groups` field as `CLUSTER`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n```\n:::\n\n\nNext, *qtm()* of **tmap** package is used to plot the choropleth map showing the cluster formed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_cluster,\"CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n> 6 clusters plot -\\> good for visual\n>\n> To convert it into map view, label it in `k = 6` and make it into factors\n>\n> Use *rename()* for tidying of field names when the matrix is combined with the geospatial data as the naming done by the *cbind()* function is not intuitive.\n\n### [Converting to sp]{.underline}\n\nFirst, we need to convert `shan_sf` into SpatialPolygonsDataFrame. This is because SKATER function only support **sp** objects such as SpatialPolygonDataFrame.\n\nThe code chunk below uses [*as_Spatial()*](https://r-spatial.github.io/sf/reference/coerce-methods.html) of **sf** package to convert *shan_sf* into a SpatialPolygonDataFrame called *shan_sp*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sp <- as_Spatial(shan_sf)\n```\n:::\n\n\n> **sf** was developed after SKATER -\\> need to convert to **sp** object (spatial polygon) first. For doing calculation.\n>\n> sp object has multiple tables -\\> separate the geometry from the rest (like shapefile, split into multiple files).\n>\n> Use **sf** format when plotting with **tmap** functions.\n\n> `ncuts = 5` starts from 0 -\\> so there are 6 clusters.\n\n## New Chapter in Hand-on Exercise 3\n\n### 9. Spatially Constrained Clustering ClustGeo Method\n\nIn this section, we gain hands-on experience on using functions of **ClustGeo** package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n### 9.1. Ward-like Hierarchical Clustering: ClustGeo\n\n**ClustGeo** package provides function called *hclustgo()* to perform a typical Ward-like hierarchical clustering, similar to *hclust()* of base R **stats**.\n\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function of a dissimilarity matrix, as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnongeo_cluster <- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster,\n            k = 6,\n            border = 2 : 5)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nNote that the dissimilarity matrix must be an object of class **dist**, i.e. an object obtained with the function *dist()*.\n\n### 9.2. Mapping the Clusters Formed\n\nSimilar to our Hands-on Exercise 3, we can plot the clusters on a categorical area shaded map by using the steps below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(nongeo_cluster, k = 6))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_ngeo_clust <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n```\n:::\n\n\nNext, *qtm()* of **tmap** package is used to plot the choropleth map showing the cluster formed. We compare this (right plot) to the hierarchical clustering `h` formed by *hclust()* of base R **stats** (left plot).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nhclustgeo.map <- qtm(shan_sf_ngeo_clust, \"CLUSTER\")\n\ntmap_arrange(hclust.map, hclustgeo.map,\n             asp=NA, ncol=2)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nWe see that clusters 3, 4 and 6 are exactly the same across both methods. Furthermore, both plots show clusters that jump across different parts of Shan State geographically.\n\n### 9.3. Spatially Constrained Hierarchical Clustering\n\nBefore we can perform spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using [*st_distance()*](https://r-spatial.github.io/sf/reference/geos_measures.html) of **sf** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist <- st_distance(shan_sf, shan_sf)\ndistmat <- as.dist(dist)\n```\n:::\n\n\nNote that *as.dist()* is used to convert the data frame into a matrix.\n\nNext, choicealpha() is used to determine a suitable value for the mixing parameter alpha, as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncr <- choicealpha(proxmat, \n                  distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K = 6, \n                  graph = TRUE)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n:::\n\n\n> `choicealpha()` is for us to balance 2 matrices.\n>\n> Balance out the homogeneity in attributes space (D0) and geographical space (spatial, e.g Queen's contiguity weight matrix) (D1).\n>\n> Ranges from 0 to 1\n>\n> 0-stage = only considering attribute space without consideration of attribute homogeneity\n>\n> 1: spatial homogeneity\n>\n> st_distance() takes the centroid of polygons\n>\n> *ClustGeo is more rigid in terms of algorithm - only accepts Ward*\n>\n> *But more flexible in terms of being able to use either contiguity-based or distance-based weight matrix*\n>\n> `seq(0, 1, 0.1)`: 0.1 = interval (increment) between 0 and 1 in the plotting\n>\n> `K = 6`: Note that \"K\" in this argument is in [**upper case**]{.underline}!! Different from *hclust()*.\n>\n> 2 graphs plotted\n>\n> 1.  1st graph based on raw\n>\n> 2.  2nd graph based on normalisation values -\\> if we find that our data is highly skewed. We will look at this in this exercise.\n>\n> Helps us determine the optimal alpha value -\\> aim is to have as high Qnorm as possible\n>\n> Based on 2nd graph: can either choose either alpha 0.2 or 0.3.\n>\n> Sharp increase in spatial homogeneity with \\<20% drop in attribute homogeneity from 0.1 to 0.2 alpha value.\n>\n> In practice, we should compare a few alpha values to see how the map changes.\n\nWith reference to the graphs above, `alpha = 0.3` will be used as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.3)\n```\n:::\n\n\nNext, *cutree()* is used to derive the cluster object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(clustG, k = 6))\n```\n:::\n\n\nWe will then join back the group list with `shan_sf` polygon feature data frame by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n```\n:::\n\n\nWe can now plot the map of the newly delineated spatially constrained clusters. We do so by comparing it (on the right plot) side-by-side with the Ward-like hierarchical clustering that we did earlier without considering the spatial component (on the left plot).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhclustgeo.map <- qtm(shan_sf_ngeo_clust, \"CLUSTER\")\n\nhclustgeo0.3.map <- qtm(shan_sf_Gcluster, \"CLUSTER\")\n\ntmap_arrange(hclustgeo.map, hclustgeo0.3.map,\n             asp=NA, ncol=2)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex3_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nWe see that now the clusters are no longer all over the place, but follows a more geospatial-related set of rules. At the same time, it is not completely geospatial either, with some clusters still spanning across different regions, e.g. cluster 4.\n\n> To interpret the clusters, we can use *heatmaply()* to study the features of each cluster, [**OR**]{.underline} do a boxplot (summary statistics) to do so.\n",
    "supporting": [
      "In-class_Ex3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}